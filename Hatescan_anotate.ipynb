{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "'''\n",
    "\n",
    "Get toxic score for the text from Hatescan API.\n",
    "The API supports english language text.\n",
    "'''\n",
    "def hatescan_toxic_classifier(text):\n",
    "    # adding \\ infront of \" in the text\n",
    "    text = text.replace('\"', '\\\\\"')\n",
    "\n",
    "    payload = '{\"text\": \"' + text +'\"}'\n",
    "\n",
    "    json_payload =json.loads(payload, strict=False)\n",
    "\n",
    "    headers={\"Content-Type\": \"application/json; charset=utf-8\"}\n",
    "\n",
    "    # Hatescan API url\n",
    "    api_hatescan_url = 'https://hatescan.dsv.su.se/predict'\n",
    "\n",
    "    # sending post request to the API\n",
    "    hatescan_response = requests.post(api_hatescan_url, headers=headers, json=json_payload)\n",
    "\n",
    "    # return toxic probability\n",
    "    return hatescan_response.json()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # TODO\n",
    "    '''\n",
    "    1) write code to read the text file with data and store the results (from the file) in a list. Each post is an entry in the list. \n",
    "    2) loop through the list to get a post and send it to the function get_toxic_probability \n",
    "    3) The function get_toxic_probability returns the probability that a post (text) is toxic\n",
    "    4) save the probability score of the post (text) together with the text in suitable format (e.g excel, tsv)\n",
    "    '''\n",
    "\n",
    "    _path = 'stormfront_2000.txt'\n",
    "    # Initialize an empty list to store the file contents\n",
    "     \n",
    "    predict, post, toxic_flag = [],[],[]\n",
    "\n",
    "    # Open the file in read mode\n",
    "    try:\n",
    "        with open(_path, 'r', encoding=\"utf-8\") as file:\n",
    "        # Read each line of the file and append it to the list\n",
    "            for line in file:\n",
    "                toxic_score = hatescan_toxic_classifier(line) \n",
    "\n",
    "                #print(toxic_score, line)\n",
    "                score = list(toxic_score.values())[0]\n",
    "\n",
    "                predict = predict + [score]\n",
    "\n",
    "                '''\n",
    "                Assiging an flag of \"1\" to a Post if it fall above the threshold, and \"0\" to Post if it fall below the thresh hold\n",
    "                This will be used to compare with the hand annotation from the 4 group Members\n",
    "                '''\n",
    "                if float(score) >= 50:\n",
    "                    _flag = 1\n",
    "                else:\n",
    "                    _flag = 0\n",
    "\n",
    "                post = post + [line]\n",
    "                toxic_flag = toxic_flag + [_flag]\n",
    "\n",
    "        #Creating a dictionary out of the 2 lists for predicted score and Post\n",
    "        content = { \"Prediction\":predict, \"Toxic ?\":toxic_flag, \"Post\":post}\n",
    "        print(content)\n",
    "\n",
    "        # Create a DataFrame from the dictionary\n",
    "        df = pd.DataFrame(content)\n",
    "\n",
    "        # Specify the Excel file name\n",
    "        excel_file = 'prediction_2000_class.xlsx'\n",
    "\n",
    "        # Write the DataFrame to an Excel file\n",
    "        df.to_excel(excel_file, index=False)\n",
    "\n",
    "        print(f'Data written to {excel_file}')\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found at path: {_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store all non toxic labeled tweets \n",
    "df0 = df[df['Toxic ?'] == 0]\n",
    "\n",
    "# Specify the Excel file name\n",
    "excel_file = 'prediction_2000_non_toxic.xlsx'\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "df0.to_excel(excel_file, index=False)\n",
    "\n",
    "# Store all toxic labeled tweets \n",
    "df1 = df[df['Toxic ?'] == 1]\n",
    "\n",
    "# Specify the Excel file name\n",
    "excel_file = 'prediction_2000_toxic.xlsx'\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "df1.to_excel(excel_file, index=False)\n",
    "\n",
    "print(f'Data written has been written')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Creating Sample files for group annotation \n",
    "'''\n",
    "Column_names = ['Suba', 'Johannes', 'Kunal', 'Joseph']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Choosing a Random sampls for both the toxic and non toxic for anotation\n",
    "The the whole sample space of the toxic coimments is been considered for annotation\n",
    "The sample from the non toxic is calculated using a confidence level of 85% with margin of error 5% \n",
    "and a population size of 1860, since we are considering thr whole predict sample of the toxic as a sample to be annotated manually\n",
    "'''\n",
    "\n",
    "# random toxic samples \n",
    "\n",
    "toxic_sample = df1\n",
    "\n",
    "# Choosing random nontoxic samples\n",
    "non_toxic_sample = df0.sample(n=187)\n",
    "\n",
    "# Randonly Combining toxic and non toxic samples to give a total of annotable samples of 327\n",
    "\n",
    "samples = pd.concat([df1, non_toxic_sample])\n",
    "samples = samples.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Add four empty columns before the last column\n",
    "for i in range(4):\n",
    "    samples.insert(len(samples.columns) - 1, Column_names[i], '')\n",
    "\n",
    "# Creating the excel file\n",
    "excel_file = 'annotate_sample.xlsx'\n",
    "\n",
    "samples.to_excel(excel_file, index=False)\n",
    "print(f'Data written to {excel_file}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
