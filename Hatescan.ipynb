{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "Get toxic score for the text from Hatescan API.\n",
    "The API supports english language text.\n",
    "'''\n",
    "def hatescan_toxic_classifier(text):\n",
    "    # adding \\ infront of \" in the text\n",
    "    text = text.replace('\"', '\\\\\"')\n",
    "\n",
    "    payload = '{\"text\": \"' + text +'\"}'\n",
    "\n",
    "    \n",
    "    json_payload =json.loads(payload, strict=False)\n",
    "\n",
    "    headers={\"Content-Type\": \"application/json; charset=utf-8\"}\n",
    "\n",
    "    # Hatescan API url\n",
    "    api_hatescan_url = 'https://hatescan.dsv.su.se/predict'\n",
    "\n",
    "    # sending post request to the API\n",
    "    hatescan_response = requests.post(api_hatescan_url, headers=headers, json=json_payload)\n",
    "\n",
    "    # return toxic probability\n",
    "    return hatescan_response.json()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # TODO\n",
    "    '''\n",
    "    1) write code to read the text file with data and store the results (from the file) in a list. Each post is an entry in the list. \n",
    "    2) loop through the list to get a post and send it to the function get_toxic_probability \n",
    "    3) The function get_toxic_probability returns the probability that a post (text) is toxic\n",
    "    4) save the probability score of the post (text) together with the text in suitable format (e.g excel, tsv)\n",
    "    '''\n",
    "\n",
    "    _path = 'stormfront.txt'\n",
    "    # Initialize an empty list to store the file contents\n",
    "     \n",
    "    predict, post = [],[]\n",
    "\n",
    "    # Open the file in read mode\n",
    "    try:\n",
    "        with open(_path, 'r', encoding=\"utf-8\") as file:\n",
    "        # Read each line of the file and append it to the list\n",
    "            for line in file:\n",
    "                toxic_score = hatescan_toxic_classifier(line) \n",
    "\n",
    "                print(toxic_score, line)\n",
    "\n",
    "                predict = predict + [list(toxic_score.values())[0]]\n",
    "                post = post + [line]\n",
    "\n",
    "        #Creating a dictionary out of the 2 lists for predicted score and Post\n",
    "        content = { \"Prediction\":predict, \"Post\":post}\n",
    "        print(content)\n",
    "\n",
    "        # Create a DataFrame from the dictionary\n",
    "        df = pd.DataFrame(content)\n",
    "\n",
    "        # Specify the Excel file name\n",
    "        excel_file = 'prediction.xlsx'\n",
    "\n",
    "        # Write the DataFrame to an Excel file\n",
    "        df.to_excel(excel_file, index=False)\n",
    "\n",
    "        print(f'Data written to {excel_file}')\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found at path: {_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
